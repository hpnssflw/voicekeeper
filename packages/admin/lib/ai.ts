/**
 * AI Service - Direct Gemini API integration for admin panel
 * Works client-side without backend dependency
 */

// Storage keys
const STORAGE_KEYS = {
  GEMINI_KEY: "voicekeeper_gemini_key",
  OPENAI_KEY: "voicekeeper_openai_key",
  AI_PROVIDER: "voicekeeper_ai_provider",
  FINGERPRINT: "voicekeeper_fingerprint",
};

export interface StyleProfile {
  tone: string;
  structure: string;
  vocabulary: string;
  signature: string;
  emoji: string;
}

export interface GenerationParams {
  topic: string;
  tone: "friendly" | "professional" | "provocative";
  length: "short" | "medium" | "long";
  includeEmoji: boolean;
  includeCta: boolean;
  customInstructions?: string;
  fingerprint?: StyleProfile;
}

export interface GenerationResult {
  content: string;
  alternatives: string[];
  confidence: number;
}

// Get/Set API keys from localStorage
export function getApiKey(provider: "gemini" | "openai"): string | null {
  if (typeof window === "undefined") return null;
  const key = provider === "gemini" ? STORAGE_KEYS.GEMINI_KEY : STORAGE_KEYS.OPENAI_KEY;
  return localStorage.getItem(key);
}

export function setApiKey(provider: "gemini" | "openai", key: string): void {
  if (typeof window === "undefined") return;
  const storageKey = provider === "gemini" ? STORAGE_KEYS.GEMINI_KEY : STORAGE_KEYS.OPENAI_KEY;
  localStorage.setItem(storageKey, key);
}

export function getAiProvider(): "gemini" | "openai" {
  if (typeof window === "undefined") return "gemini";
  return (localStorage.getItem(STORAGE_KEYS.AI_PROVIDER) as "gemini" | "openai") || "gemini";
}

export function setAiProvider(provider: "gemini" | "openai"): void {
  if (typeof window === "undefined") return;
  localStorage.setItem(STORAGE_KEYS.AI_PROVIDER, provider);
}

// Get/Set fingerprint from localStorage
export function getFingerprint(): StyleProfile | null {
  if (typeof window === "undefined") return null;
  const data = localStorage.getItem(STORAGE_KEYS.FINGERPRINT);
  return data ? JSON.parse(data) : null;
}

export function setFingerprint(profile: StyleProfile): void {
  if (typeof window === "undefined") return;
  localStorage.setItem(STORAGE_KEYS.FINGERPRINT, JSON.stringify(profile));
}

// Get available Gemini models
async function getAvailableModels(apiKey: string): Promise<string[]> {
  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`
    );
    if (response.ok) {
      const data = await response.json();
      return (data.models || [])
        .filter((m: any) => m.supportedGenerationMethods?.includes('generateContent'))
        .map((m: any) => m.name.replace('models/', ''));
    }
  } catch {
    // Fallback to default models if list fails
  }
  // Default fallback models (most common)
  return ['gemma-3-1b-it', 'gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro'];
}

// Gemini API call
async function callGemini(prompt: string, apiKey: string): Promise<string> {
  // Get available models first
  const models = await getAvailableModels(apiKey);
  
  // Add gemma-3-1b-it to the list if not already present
  if (!models.includes('gemma-3-1b-it')) {
    models.unshift('gemma-3-1b-it'); // Prioritize it
  }
  
  // Try different API versions and models
  const apiVersions = ['v1beta', 'v1']; // Prioritize v1beta for gemma
  let lastError: Error | null = null;

  for (const version of apiVersions) {
    for (const model of models) {
      try {
        const endpoint = `https://generativelanguage.googleapis.com/${version}/models/${model}:generateContent?key=${apiKey}`;
        const response = await fetch(endpoint, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            contents: [{ parts: [{ text: prompt }] }],
            generationConfig: {
              temperature: 0.8,
              maxOutputTokens: 2048,
            },
          }),
        });

        if (!response.ok) {
          const error = await response.json();
          lastError = new Error(error.error?.message || "Gemini API error");
          continue; // Try next model/version
        }

        const data = await response.json();
        const text = data.candidates?.[0]?.content?.parts?.[0]?.text || "";
        if (text) {
          return text;
        }
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        continue; // Try next model/version
      }
    }
  }

  // If all attempts failed, throw the last error
  throw lastError || new Error("Gemini API error: All models and versions failed. Please check your API key and available models.");
}

// Analyze style from text
export async function analyzeStyle(text: string): Promise<StyleProfile> {
  const apiKey = getApiKey("gemini");
  if (!apiKey) {
    throw new Error("API –∫–ª—é—á Gemini –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Üí API –∫–ª—é—á–∏.");
  }

  const prompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –∞–≤—Ç–æ—Ä—Å–∫–∏–π —Å—Ç–∏–ª—å. –í–µ—Ä–Ω–∏ JSON –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª—è–º–∏:
- tone: –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π")
- structure: –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ö–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã, —Å–ø–∏—Å–∫–∏")
- vocabulary: –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å —É–ø—Ä–æ—â–µ–Ω–∏—è–º–∏")
- signature: —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Ñ–∏—à–∫–∏ —Å—Ç–∏–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–ù–∞—á–∏–Ω–∞–µ—Ç —Å –≤–æ–ø—Ä–æ—Å–∞, –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç CTA")
- emoji: —Ç–∏–ø–∏—á–Ω—ã–µ —ç–º–æ–¥–∑–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: "üî• üí° ‚úÖ")

–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
"""
${text}
"""

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown:`;

  const result = await callGemini(prompt, apiKey);
  
  // Parse JSON from response
  try {
    // Try to extract JSON from response
    const jsonMatch = result.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
    throw new Error("No JSON found");
  } catch {
    // Fallback parsing
    return {
      tone: "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å",
      structure: "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å",
      vocabulary: "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å",
      signature: "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å",
      emoji: "üìù",
    };
  }
}

// Generate post content
export async function generatePost(params: GenerationParams): Promise<GenerationResult> {
  const apiKey = getApiKey("gemini");
  if (!apiKey) {
    throw new Error("API –∫–ª—é—á Gemini –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ‚Üí API –∫–ª—é—á–∏.");
  }

  const lengthGuide = {
    short: "150-250 —Å–∏–º–≤–æ–ª–æ–≤",
    medium: "400-600 —Å–∏–º–≤–æ–ª–æ–≤", 
    long: "800-1200 —Å–∏–º–≤–æ–ª–æ–≤",
  };

  const toneGuide = {
    friendly: "–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, —Ç—ë–ø–ª—ã–π, –∫–∞–∫ —Ä–∞–∑–≥–æ–≤–æ—Ä —Å –¥—Ä—É–≥–æ–º",
    professional: "—ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π, –¥–µ–ª–æ–≤–æ–π, –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π",
    provocative: "–ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–π, –≤—ã–∑—ã–≤–∞—é—â–∏–π, —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π",
  };

  let fingerprintContext = "";
  if (params.fingerprint) {
    fingerprintContext = `
–°—Ç–∏–ª—å –∞–≤—Ç–æ—Ä–∞ (Voice Fingerprint):
- –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: ${params.fingerprint.tone}
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: ${params.fingerprint.structure}
- –°–ª–æ–≤–∞—Ä—å: ${params.fingerprint.vocabulary}
- –§–∏—à–∫–∏: ${params.fingerprint.signature}
- –≠–º–æ–¥–∑–∏: ${params.fingerprint.emoji}

–í–∞–∂–Ω–æ: –ö–æ–ø–∏—Ä—É–π —ç—Ç–æ—Ç —Å—Ç–∏–ª—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ!
`;
  }

  const prompt = `–¢—ã ‚Äî –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–æ–≤. –ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç –Ω–∞ —Ç–µ–º—É: "${params.topic}"

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –î–ª–∏–Ω–∞: ${lengthGuide[params.length]}
- –¢–æ–Ω: ${toneGuide[params.tone]}
- –≠–º–æ–¥–∑–∏: ${params.includeEmoji ? "–∏—Å–ø–æ–ª—å–∑—É–π —É–º–µ—Å—Ç–Ω–æ, –Ω–µ –ø–µ—Ä–µ–±–∞—Ä—â–∏–≤–∞–π" : "–ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏"}
- –ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é: ${params.includeCta ? "–¥–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ" : "–Ω–µ –Ω—É–∂–µ–Ω"}
${params.customInstructions ? `- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: ${params.customInstructions}` : ""}
${fingerprintContext}

–ù–∞–ø–∏—à–∏ –ø–æ—Å—Ç (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫, –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ "–ü–æ—Å—Ç:", –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞):`;

  const mainContent = await callGemini(prompt, apiKey);

  // Generate one alternative
  const altPrompt = `${prompt}\n\n–≠—Ç–æ –≤—Ç–æ—Ä–æ–π –≤–∞—Ä–∏–∞–Ω—Ç, —Å–¥–µ–ª–∞–π –µ–≥–æ –Ω–µ–º–Ω–æ–≥–æ –¥—Ä—É–≥–∏–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:`;
  let alternative = "";
  try {
    alternative = await callGemini(altPrompt, apiKey);
  } catch {
    // Ignore alternative generation errors
  }

  return {
    content: mainContent.trim(),
    alternatives: alternative ? [alternative.trim()] : [],
    confidence: 85 + Math.floor(Math.random() * 10),
  };
}

// Test API key
export async function testApiKey(provider: "gemini" | "openai", key: string): Promise<boolean> {
  if (provider === "gemini") {
    try {
      // First try to get available models
      const models = await getAvailableModels(key);
      
      // Add gemma-3-1b-it to the list if not already present
      const modelsToTest = models.includes('gemma-3-1b-it') 
        ? models 
        : ['gemma-3-1b-it', ...models];
      
      const apiVersions = ['v1beta', 'v1']; // Prioritize v1beta for gemma
      
      for (const version of apiVersions) {
        for (const model of models.slice(0, 3)) { // Try first 3 models
          try {
            const endpoint = `https://generativelanguage.googleapis.com/${version}/models/${model}:generateContent?key=${key}`;
            const response = await fetch(endpoint, {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                contents: [{ parts: [{ text: "Test" }] }],
              }),
            });
            if (response.ok) {
              await response.json();
              return true;
            }
          } catch {
            continue; // Try next model/version
          }
        }
      }
      return false;
    } catch {
      return false;
    }
  }
  // OpenAI test would go here
  return false;
}

